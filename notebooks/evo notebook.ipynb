{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evo notebook\n",
    "\n",
    "This notebook tries to run the Evo model\n",
    "\n",
    "https://huggingface.co/togethercomputer/evo-1-8k-base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install flash_attn\n",
    "!pip install evo-model\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2965044894.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    config.\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "config = dotenv.load_dotenv()\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Hugging Face cache directory: C:\\Users\\dallo\\.cache\\huggingface\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHugging Face cache directory not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Attempt to load the model again\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[43mmodel_name\u001b[49m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, revision\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1_fix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     18\u001b[0m     model_name,\n\u001b[0;32m     19\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     token\u001b[38;5;241m=\u001b[39mhf_token  \u001b[38;5;66;03m# Assuming you have `hf_token` defined\u001b[39;00m\n\u001b[0;32m     23\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_name' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM, pipeline\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Path to the Hugging Face cache directory\n",
    "cache_dir = os.path.join(os.path.expanduser(\"~\"), \".cache\", \"huggingface\")\n",
    "\n",
    "# Remove the cache directory\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "    print(f\"Removed Hugging Face cache directory: {cache_dir}\")\n",
    "else:\n",
    "    print(f\"Hugging Face cache directory not found: {cache_dir}\")\n",
    "\n",
    "# Attempt to load the model again\n",
    "config = AutoConfig.from_pretrained(model_name, trust_remote_code=True, revision=\"1.1_fix\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    "    trust_remote_code=True,\n",
    "    revision=\"1.1_fix\",\n",
    "    token=hf_token  # Assuming you have `hf_token` defined\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
